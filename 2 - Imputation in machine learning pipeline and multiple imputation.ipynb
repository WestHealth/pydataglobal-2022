{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TopzKHmOtVtL"
   },
   "source": [
    "## $\\color{purple}{\\text{Missing Data in the Age of Machine Learning and Artifical Neural Network (part 2)}}$\n",
    "\n",
    "## $\\color{purple}{\\text{Imputation in Machine Learning and Multiple Imputation}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILSdXRpPtiU8"
   },
   "source": [
    "## $\\color{purple}{\\text{How Imputation Fits Into Your Machine Learning Models}}$\n",
    "\n",
    "### Typical Machine Learning Workflow: \n",
    "  * Encoding\n",
    "  * Preprocessing\n",
    "  * Train\n",
    "  * Test\n",
    "  * Use\n",
    "  \n",
    "![](https://raw.githubusercontent.com/WestHealth/pydataglobal-2022/main/images/typical.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILSdXRpPtiU8"
   },
   "source": [
    "### Machine Learning Workflow with Imputation: \n",
    "\n",
    "  * Encoding\n",
    "  * Preprocessing\n",
    "  * *Imputater*\n",
    "  * Train\n",
    "  * Test\n",
    "  * Use\n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/WestHealth/pydataglobal-2022/main/images/imputer.svg)\n",
    "\n",
    "\n",
    "* We demonstrate this using `sklearn`'s pipeline. But this is meant to describe abstractly what you should do\n",
    "\n",
    "Same data set is taken from the [Wine Quality Dataset at UCI](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "This demonstrates a typical pipeline. The final column `quality` is the predicted value (ranging from 1 - 9). The `features` variable contains all the other column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{purple}{\\text{Libraries for this lesson}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from autoimpute.imputations import MiceImputer\n",
    "from autoimpute.imputations import SingleImputer\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0AcjuKGBZBDN"
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('data/original_wine_training.csv')\n",
    "test = pd.read_csv('data/original_wine_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.082</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.7</td>\n",
       "      <td>red</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.052</td>\n",
       "      <td>55.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.9</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.123</td>\n",
       "      <td>27.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.4</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.37</td>\n",
       "      <td>16.95</td>\n",
       "      <td>0.048</td>\n",
       "      <td>43.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.99950</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.2</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.028</td>\n",
       "      <td>32.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.1</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.062</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.5</td>\n",
       "      <td>red</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>red</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.036</td>\n",
       "      <td>35.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.98936</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.44</td>\n",
       "      <td>13.5</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.27</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>46.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.2</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.039</td>\n",
       "      <td>36.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99059</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.1</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               8.0             0.500         0.39            2.60      0.082   \n",
       "1               6.6             0.280         0.28            8.50      0.052   \n",
       "2               7.0             0.190         0.23            5.70      0.123   \n",
       "3               7.4             0.200         0.37           16.95      0.048   \n",
       "4               7.8             0.280         0.34            1.60      0.028   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4995            9.8             0.300         0.39            1.70      0.062   \n",
       "4996            8.3             0.845         0.01            2.20      0.070   \n",
       "4997            7.1             0.360         0.28            2.40      0.036   \n",
       "4998            6.6             0.240         0.27           15.80      0.035   \n",
       "4999            6.9             0.300         0.45            1.40      0.039   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    12.0                  46.0  0.99850  3.43       0.62   \n",
       "1                    55.0                 211.0  0.99620  3.09       0.55   \n",
       "2                    27.0                 104.0  0.99540  3.04       0.54   \n",
       "3                    43.0                 190.0  0.99950  3.03       0.42   \n",
       "4                    32.0                 118.0  0.99010  3.00       0.38   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4995                  3.0                   9.0  0.99480  3.14       0.57   \n",
       "4996                  5.0                  14.0  0.99670  3.32       0.58   \n",
       "4997                 35.0                 115.0  0.98936  3.19       0.44   \n",
       "4998                 46.0                 188.0  0.99820  3.24       0.51   \n",
       "4999                 36.0                 122.0  0.99059  3.07       0.47   \n",
       "\n",
       "      alcohol   type  quality  \n",
       "0        10.7    red        6  \n",
       "1         8.9  white        6  \n",
       "2         9.4  white        6  \n",
       "3         9.2  white        6  \n",
       "4        12.1  white        7  \n",
       "...       ...    ...      ...  \n",
       "4995     11.5    red        7  \n",
       "4996     11.0    red        4  \n",
       "4997     13.5  white        7  \n",
       "4998      9.2  white        5  \n",
       "4999     11.1  white        7  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'type']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(training.columns[0:-1])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical ML Workflow\n",
    "\n",
    "We build the pipeline by one-hot encoding the `type` column which is categorical, then scale it, then apply random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([(\"type\", OneHotEncoder(), [\"type\"])],remainder='passthrough'), \n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;type&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;type&#x27;])])),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;type&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;type&#x27;])])),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;type&#x27;, OneHotEncoder(), [&#x27;type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">type</label><div class=\"sk-toggleable__content\"><pre>[&#x27;type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;, &#x27;chlorides&#x27;, &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;, &#x27;sulphates&#x27;, &#x27;alcohol&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('type', OneHotEncoder(),\n",
       "                                                  ['type'])])),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(training[features], training['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5401247706611145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test[features], test['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZZt4mf7mpd6"
   },
   "source": [
    "### ML Workflow with Imputer\n",
    "\n",
    "Note: This is meant to demonstrate workflow and `autoimpute` is used as an example.\n",
    "\n",
    "One drawback is that `autoimpute` imputers require a `pandas` `DataFrame` as an input so custom transformers need to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_hack = FunctionTransformer(\n",
    "    lambda x: pd.DataFrame(x, columns=['type_r', 'type_w'] + features[0:-1]))\n",
    "pandas_hack_full = FunctionTransformer(\n",
    "    lambda x: pd.DataFrame(x, columns=['type_r', 'type_w'] + features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert the imputer into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([(\"type\", OneHotEncoder(), ['type'])],remainder='passthrough'), \n",
    "    pandas_hack,\n",
    "    SingleImputer(strategy='least squares'), \n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;type&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;type&#x27;])])),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7f44e5573b80&gt;)),\n",
       "                (&#x27;singleimputer&#x27;, SingleImputer(strategy=&#x27;least squares&#x27;)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;type&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;type&#x27;])])),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7f44e5573b80&gt;)),\n",
       "                (&#x27;singleimputer&#x27;, SingleImputer(strategy=&#x27;least squares&#x27;)),\n",
       "                (&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;type&#x27;, OneHotEncoder(), [&#x27;type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">type</label><div class=\"sk-toggleable__content\"><pre>[&#x27;type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fixed acidity&#x27;, &#x27;volatile acidity&#x27;, &#x27;citric acid&#x27;, &#x27;residual sugar&#x27;, &#x27;chlorides&#x27;, &#x27;free sulfur dioxide&#x27;, &#x27;total sulfur dioxide&#x27;, &#x27;density&#x27;, &#x27;pH&#x27;, &#x27;sulphates&#x27;, &#x27;alcohol&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x7f44e5573b80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SingleImputer</label><div class=\"sk-toggleable__content\"><pre>SingleImputer(strategy=&#x27;least squares&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('type', OneHotEncoder(),\n",
       "                                                  ['type'])])),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f44e5573b80>)),\n",
       "                ('singleimputer', SingleImputer(strategy='least squares')),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_training = pd.read_csv('data/wine_training.csv')\n",
    "pipeline.fit(wine_training[features], wine_training['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46757083737038485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_test = pd.read_csv('data/wine_test.csv')\n",
    "pipeline.score(wine_test[features], wine_test['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61, 6.49, 5.14, 4.73, 5.64, 5.08, 4.73, 5.34, 5.52, 6.32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_future = pd.read_csv('data/wine_future.csv')\n",
    "pipeline.predict(wine_future[features].iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{purple}{\\text{How does Multiple Imputation fit in?}}$\n",
    "### $\\color{purple}{\\text{Approach 1: Augment Data with Multiple Copies}}$\n",
    "\n",
    "![](https://raw.githubusercontent.com/WestHealth/pydataglobal-2022/main/images/stack.svg)\n",
    "\n",
    "Augmentation teachs the model that the imputed values are \"fuzzy\" by providing different values.\n",
    "\n",
    "We create the same pipeline except we have a MiceImputer at the end.\n",
    "The resultant `dfs` are 5 copies of our dataframe with 5 separate imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2640,
     "status": "ok",
     "timestamp": 1654712480068,
     "user": {
      "displayName": "Haw-minn Lu",
      "userId": "16109571175851064283"
     },
     "user_tz": 420
    },
    "id": "zwFrIcTcm87_",
    "outputId": "bf99ee06-2531-437c-988b-c1bd2d87652e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataframe: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_r</th>\n",
       "      <th>type_w</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>0.596969</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.494524</td>\n",
       "      <td>-0.601330</td>\n",
       "      <td>0.710839</td>\n",
       "      <td>-1.061784</td>\n",
       "      <td>-1.227729</td>\n",
       "      <td>1.253843</td>\n",
       "      <td>1.311354</td>\n",
       "      <td>0.587923</td>\n",
       "      <td>0.178056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.468202</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>-0.276098</td>\n",
       "      <td>0.631424</td>\n",
       "      <td>-0.111443</td>\n",
       "      <td>1.399135</td>\n",
       "      <td>1.687875</td>\n",
       "      <td>0.494073</td>\n",
       "      <td>-0.801990</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>-1.335505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.163867</td>\n",
       "      <td>-0.901984</td>\n",
       "      <td>-0.626381</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>1.834623</td>\n",
       "      <td>-0.203323</td>\n",
       "      <td>-0.202850</td>\n",
       "      <td>0.229805</td>\n",
       "      <td>0.289512</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>-0.915071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>0.140467</td>\n",
       "      <td>-0.840961</td>\n",
       "      <td>0.354411</td>\n",
       "      <td>2.396979</td>\n",
       "      <td>-0.221080</td>\n",
       "      <td>0.712367</td>\n",
       "      <td>1.316798</td>\n",
       "      <td>1.584178</td>\n",
       "      <td>-1.174933</td>\n",
       "      <td>-0.747590</td>\n",
       "      <td>-1.083245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>0.444802</td>\n",
       "      <td>-0.352782</td>\n",
       "      <td>0.144241</td>\n",
       "      <td>-0.810271</td>\n",
       "      <td>-0.769268</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>-1.520970</td>\n",
       "      <td>-1.361404</td>\n",
       "      <td>-1.014692</td>\n",
       "      <td>1.355271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>1.966474</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>0.494524</td>\n",
       "      <td>-0.789377</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>-1.576860</td>\n",
       "      <td>-1.881532</td>\n",
       "      <td>0.031604</td>\n",
       "      <td>-0.491204</td>\n",
       "      <td>0.254044</td>\n",
       "      <td>0.850750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>0.825220</td>\n",
       "      <td>3.094987</td>\n",
       "      <td>-2.167626</td>\n",
       "      <td>-0.684907</td>\n",
       "      <td>0.381926</td>\n",
       "      <td>-1.462398</td>\n",
       "      <td>-1.793180</td>\n",
       "      <td>0.659240</td>\n",
       "      <td>0.627625</td>\n",
       "      <td>0.320820</td>\n",
       "      <td>0.430316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.087784</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>-0.276098</td>\n",
       "      <td>-0.643118</td>\n",
       "      <td>-0.549993</td>\n",
       "      <td>0.254522</td>\n",
       "      <td>-0.008477</td>\n",
       "      <td>-1.765417</td>\n",
       "      <td>-0.180418</td>\n",
       "      <td>0.588223</td>\n",
       "      <td>2.532485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.468202</td>\n",
       "      <td>-0.596872</td>\n",
       "      <td>-0.346155</td>\n",
       "      <td>1.150729</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>0.884059</td>\n",
       "      <td>0.723583</td>\n",
       "      <td>1.154742</td>\n",
       "      <td>1.431114</td>\n",
       "      <td>-0.146609</td>\n",
       "      <td>-1.083245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.239951</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>0.914864</td>\n",
       "      <td>-0.852060</td>\n",
       "      <td>-0.467765</td>\n",
       "      <td>-0.381462</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>-1.103719</td>\n",
       "      <td>-0.926304</td>\n",
       "      <td>-0.413712</td>\n",
       "      <td>0.735474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_r    type_w  fixed acidity  volatile acidity  citric acid  \\\n",
       "0     1.753562 -1.753562       0.596969          0.989712     0.494524   \n",
       "1    -0.570268  0.570268      -0.468202          0.008971    -0.276098   \n",
       "2    -0.570268  0.570268      -0.163867         -0.901984    -0.626381   \n",
       "3    -0.570268  0.570268       0.140467         -0.840961     0.354411   \n",
       "4    -0.570268  0.570268       0.444802         -0.352782     0.144241   \n",
       "...        ...       ...            ...               ...          ...   \n",
       "4995  1.753562 -1.753562       1.966474         -0.230737     0.494524   \n",
       "4996  1.753562 -1.753562       0.825220          3.094987    -2.167626   \n",
       "4997 -0.570268  0.570268      -0.087784          0.135398    -0.276098   \n",
       "4998 -0.570268  0.570268      -0.468202         -0.596872    -0.346155   \n",
       "4999 -0.570268  0.570268      -0.239951         -0.230737     0.914864   \n",
       "\n",
       "      residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0          -0.601330   0.710839            -1.061784             -1.227729   \n",
       "1           0.631424  -0.111443             1.399135              1.687875   \n",
       "2           0.046388   1.834623            -0.203323             -0.202850   \n",
       "3           2.396979  -0.221080             0.712367              1.316798   \n",
       "4          -0.810271  -0.769268             0.082830              0.044534   \n",
       "...              ...        ...                  ...                   ...   \n",
       "4995       -0.789377   0.162651            -1.576860             -1.881532   \n",
       "4996       -0.684907   0.381926            -1.462398             -1.793180   \n",
       "4997       -0.643118  -0.549993             0.254522             -0.008477   \n",
       "4998        1.150729  -0.577402             0.884059              0.723583   \n",
       "4999       -0.852060  -0.467765            -0.381462              0.115215   \n",
       "\n",
       "       density        pH  sulphates   alcohol  \n",
       "0     1.253843  1.311354   0.587923  0.178056  \n",
       "1     0.494073 -0.801990   0.120493 -1.335505  \n",
       "2     0.229805  0.289512   0.053718 -0.915071  \n",
       "3     1.584178 -1.174933  -0.747590 -1.083245  \n",
       "4    -1.520970 -1.361404  -1.014692  1.355271  \n",
       "...        ...       ...        ...       ...  \n",
       "4995  0.031604 -0.491204   0.254044  0.850750  \n",
       "4996  0.659240  0.627625   0.320820  0.430316  \n",
       "4997 -1.765417 -0.180418   0.588223  2.532485  \n",
       "4998  1.154742  1.431114  -0.146609 -1.083245  \n",
       "4999 -1.103719 -0.926304  -0.413712  0.735474  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([(\"type\", OneHotEncoder(), ['type'])],remainder='passthrough'), \n",
    "    StandardScaler(), \n",
    "    pandas_hack,\n",
    "    MiceImputer(k=5, strategy='stochastic'))\n",
    "\n",
    "dfs = [each[1] for each in pipeline.fit_transform(wine_training[features])]\n",
    "print('Number of dataframe: ' + str(len(dfs)))\n",
    "\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdHaAdHHm38b"
   },
   "source": [
    "We augment the training set by concatenating the 5 different data frame. Equivalently, we could rotate each epoch with different imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_training = pd.concat(dfs)\n",
    "\n",
    "quality = pd.concat([\n",
    "    wine_training.quality, wine_training.quality, wine_training.quality,\n",
    "    wine_training.quality, wine_training.quality\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_r</th>\n",
       "      <th>type_w</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>0.596969</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.494524</td>\n",
       "      <td>-0.601330</td>\n",
       "      <td>0.710839</td>\n",
       "      <td>-1.061784</td>\n",
       "      <td>-1.227729</td>\n",
       "      <td>1.253843</td>\n",
       "      <td>1.311354</td>\n",
       "      <td>0.587923</td>\n",
       "      <td>0.178056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.468202</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>-0.276098</td>\n",
       "      <td>0.631424</td>\n",
       "      <td>-0.111443</td>\n",
       "      <td>1.399135</td>\n",
       "      <td>1.687875</td>\n",
       "      <td>0.494073</td>\n",
       "      <td>-0.801990</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>-1.335505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.163867</td>\n",
       "      <td>-0.901984</td>\n",
       "      <td>-0.626381</td>\n",
       "      <td>0.046388</td>\n",
       "      <td>1.834623</td>\n",
       "      <td>-0.203323</td>\n",
       "      <td>-0.202850</td>\n",
       "      <td>0.229805</td>\n",
       "      <td>0.289512</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>-0.915071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>0.140467</td>\n",
       "      <td>-0.840961</td>\n",
       "      <td>0.354411</td>\n",
       "      <td>2.396979</td>\n",
       "      <td>-0.221080</td>\n",
       "      <td>0.712367</td>\n",
       "      <td>1.316798</td>\n",
       "      <td>1.584178</td>\n",
       "      <td>-1.174933</td>\n",
       "      <td>-0.747590</td>\n",
       "      <td>-1.083245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>0.444802</td>\n",
       "      <td>-0.352782</td>\n",
       "      <td>0.144241</td>\n",
       "      <td>-0.810271</td>\n",
       "      <td>-0.769268</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>-1.520970</td>\n",
       "      <td>-1.361404</td>\n",
       "      <td>-1.014692</td>\n",
       "      <td>1.355271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>1.966474</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>0.494524</td>\n",
       "      <td>-0.789377</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>-1.576860</td>\n",
       "      <td>-1.881532</td>\n",
       "      <td>0.031604</td>\n",
       "      <td>-0.491204</td>\n",
       "      <td>0.254044</td>\n",
       "      <td>0.850750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.753562</td>\n",
       "      <td>-1.753562</td>\n",
       "      <td>0.825220</td>\n",
       "      <td>3.094987</td>\n",
       "      <td>-2.167626</td>\n",
       "      <td>-0.684907</td>\n",
       "      <td>0.381926</td>\n",
       "      <td>-1.462398</td>\n",
       "      <td>-1.793180</td>\n",
       "      <td>0.659240</td>\n",
       "      <td>0.627625</td>\n",
       "      <td>0.320820</td>\n",
       "      <td>0.430316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.087784</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>-0.276098</td>\n",
       "      <td>-0.643118</td>\n",
       "      <td>-0.549993</td>\n",
       "      <td>0.254522</td>\n",
       "      <td>-0.008477</td>\n",
       "      <td>-1.765417</td>\n",
       "      <td>-0.180418</td>\n",
       "      <td>-0.563210</td>\n",
       "      <td>2.532485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.468202</td>\n",
       "      <td>-0.596872</td>\n",
       "      <td>-0.346155</td>\n",
       "      <td>1.326150</td>\n",
       "      <td>-0.577402</td>\n",
       "      <td>0.884059</td>\n",
       "      <td>1.291953</td>\n",
       "      <td>1.154742</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>-0.146609</td>\n",
       "      <td>-1.083245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.570268</td>\n",
       "      <td>0.570268</td>\n",
       "      <td>-0.239951</td>\n",
       "      <td>-0.230737</td>\n",
       "      <td>0.914864</td>\n",
       "      <td>-0.852060</td>\n",
       "      <td>-0.467765</td>\n",
       "      <td>-1.734692</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>-1.085159</td>\n",
       "      <td>-0.926304</td>\n",
       "      <td>-0.413712</td>\n",
       "      <td>-0.049504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_r    type_w  fixed acidity  volatile acidity  citric acid  \\\n",
       "0     1.753562 -1.753562       0.596969          0.989712     0.494524   \n",
       "1    -0.570268  0.570268      -0.468202          0.008971    -0.276098   \n",
       "2    -0.570268  0.570268      -0.163867         -0.901984    -0.626381   \n",
       "3    -0.570268  0.570268       0.140467         -0.840961     0.354411   \n",
       "4    -0.570268  0.570268       0.444802         -0.352782     0.144241   \n",
       "...        ...       ...            ...               ...          ...   \n",
       "4995  1.753562 -1.753562       1.966474         -0.230737     0.494524   \n",
       "4996  1.753562 -1.753562       0.825220          3.094987    -2.167626   \n",
       "4997 -0.570268  0.570268      -0.087784          0.135398    -0.276098   \n",
       "4998 -0.570268  0.570268      -0.468202         -0.596872    -0.346155   \n",
       "4999 -0.570268  0.570268      -0.239951         -0.230737     0.914864   \n",
       "\n",
       "      residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0          -0.601330   0.710839            -1.061784             -1.227729   \n",
       "1           0.631424  -0.111443             1.399135              1.687875   \n",
       "2           0.046388   1.834623            -0.203323             -0.202850   \n",
       "3           2.396979  -0.221080             0.712367              1.316798   \n",
       "4          -0.810271  -0.769268             0.082830              0.044534   \n",
       "...              ...        ...                  ...                   ...   \n",
       "4995       -0.789377   0.162651            -1.576860             -1.881532   \n",
       "4996       -0.684907   0.381926            -1.462398             -1.793180   \n",
       "4997       -0.643118  -0.549993             0.254522             -0.008477   \n",
       "4998        1.326150  -0.577402             0.884059              1.291953   \n",
       "4999       -0.852060  -0.467765            -1.734692              0.115215   \n",
       "\n",
       "       density        pH  sulphates   alcohol  \n",
       "0     1.253843  1.311354   0.587923  0.178056  \n",
       "1     0.494073 -0.801990   0.120493 -1.335505  \n",
       "2     0.229805  0.289512   0.053718 -0.915071  \n",
       "3     1.584178 -1.174933  -0.747590 -1.083245  \n",
       "4    -1.520970 -1.361404  -1.014692  1.355271  \n",
       "...        ...       ...        ...       ...  \n",
       "4995  0.031604 -0.491204   0.254044  0.850750  \n",
       "4996  0.659240  0.627625   0.320820  0.430316  \n",
       "4997 -1.765417 -0.180418  -0.563210  2.532485  \n",
       "4998  1.154742  0.894511  -0.146609 -1.083245  \n",
       "4999 -1.085159 -0.926304  -0.413712 -0.049504  \n",
       "\n",
       "[25000 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since test set is used to evaluate when the model may hit overtraining, it is not necessary to multiply impute the tests. But you may."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = [each[1] for each in pipeline.transform(wine_test[features])]\n",
    "\n",
    "test1 = test_dfs[0]  # Variation one, just take one imputation\n",
    "quality1 = wine_test.quality\n",
    "\n",
    "test2 = pd.concat(test_dfs)  # Variation two augment in the same way\n",
    "quality2 = pd.concat([quality1, quality1, quality1, quality1, quality1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(augmented_training, quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4577084922385537"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test1, quality1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46220538972149505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test2, quality2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsfJcQLfm9rh"
   },
   "source": [
    "Here we show an additional example of using neural networks to predict the imputed dataset. The network model was built as a classification problem. Bear in mind this is just for demonstration purposes, our model is not a particularly good estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 16:44:32.377750: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 16:44:32.386988: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Approach\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "e8ZUY3sEjJax"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44d82e6760>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(augmented_training, quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0316 - accuracy: 0.5330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0315864086151123, 0.5329999923706055]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test1, quality1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 1.0340 - accuracy: 0.5332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0339940786361694, 0.5332000255584717]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test2, quality2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about future values?\n",
    "Same options:\n",
    " * take one imputation\n",
    " * run all imputations through the model and use an ensemble technique to combine (e.g., majority voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([(\"type\", OneHotEncoder(), ['type'])],remainder='passthrough'), \n",
    "    StandardScaler(), \n",
    "    pandas_hack,\n",
    "    MiceImputer(k=5, strategy='stochastic'))\n",
    "\n",
    "future_dfs = [\n",
    "    each[1].iloc[[0]] for each in pipeline.fit_transform(wine_future[features])\n",
    "]\n",
    "\n",
    "future1 = future_dfs[0]  # Variation one, just take one imputation\n",
    "future2 = pd.concat(future_dfs)  # Variation two augment in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9242957e-05, 3.3287535e-05, 2.4239307e-05, 9.2014414e-04,\n",
       "        4.7006989e-03, 1.5112912e-02, 2.2790848e-01, 5.7404137e-01,\n",
       "        1.7503612e-01, 2.1735001e-03]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(future1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variation 1: Pick First Imputed\n",
    "# Argmax was used because the model predicted one-hot encoded label (i.e. 000000100 for 7)\n",
    "\n",
    "np.argmax(model.predict(future1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthy to mention that here we simply take the sum to aggregate 5 imputation results. In practice, you can use other more robusted methods such as majority vote, averaging, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variation 2: Aggregate all Imputed\n",
    "np.argmax(model.predict(future2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{purple}{\\text{Approach 2: Combine Multiple Models}}$\n",
    "\n",
    "![](https://raw.githubusercontent.com/WestHealth/pydataglobal-2022/main/images/ensemble.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]) for _ in range(0, 5)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model is trained on a different imputation model. Each model should be tested under each imputation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: dfs stores a list of 5 imputed dataframes that was done indepdently\n",
    "\n",
    "for model, training in zip(models, dfs):\n",
    "    model.fit(training, wine_training.quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0760548114776611, 0.5329999923706055]\n",
      "[1.075652003288269, 0.5199999809265137]\n",
      "[1.0803433656692505, 0.5040000081062317]\n",
      "[1.063344955444336, 0.5260000228881836]\n",
      "[1.0697463750839233, 0.5429999828338623]\n"
     ]
    }
   ],
   "source": [
    "for model, test in zip(models, test_dfs):\n",
    "    print(model.evaluate(test, wine_test.quality, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f44ad0fcf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f44ad0e2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# np vstack turns the list of arrays into an array of arrays\n",
    "predictions = np.vstack(\n",
    "    [model.predict(future) for model, future in zip(models, future_dfs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate predictions\n",
    "np.argmax(predictions.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{purple}{\\text{Worth Mentioning: Use Single Imputation with Bagging}}$\n",
    "Short for bootstrap and aggregation\n",
    "\n",
    "Rather than multiple imputation, single imputations are performed from resampled datasets (bootstrapping)\n",
    "\n",
    "![](https://raw.githubusercontent.com/WestHealth/pydataglobal-2022/main/images/single.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([(\"type\", OneHotEncoder(), ['type'])],remainder='passthrough'), \n",
    "    StandardScaler(),\n",
    "    pandas_hack_full, \n",
    "    MiceImputer(k=1, strategy='stochastic')\n",
    ")\n",
    "\n",
    "bagged_dfs = [\n",
    "    next(pipeline.fit_transform(wine_training.sample(frac=1, replace=True)))[1]\n",
    "    for _ in range(0, 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]) for _ in range(0, 5)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, training in zip(models, dfs):\n",
    "    model.fit(training, wine_training.quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.vstack(\n",
    "    [model.predict(future) for model, future in zip(models, future_dfs)])\n",
    "# Aggregate predictions\n",
    "np.argmax(predictions.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{purple}{\\text{Conclusion}}$\n",
    "\n",
    "* In a typical machine learning pipeline, imputation should be done before feeding into the machine learning model \n",
    "\n",
    "* Several strategies for multiple imputations:\n",
    "  * Augmenting dataset multiple times and predicted by the same imputer \n",
    "  * Perform imputation multiple times with independent imputer\n",
    "  * Bagging can be applied to single imputation performed multiply\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "authorship_tag": "ABX9TyPpLv6R3L0XkmwitYmu11KS",
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
